#jdbc hubble数据库配置
jdbc.datasource.size=5
jdbc.hubble.driver=com.beagledata.hubble.jdbc.HubbleDriver
jdbc.hubble.url=jdbc:hubble://10.20.147.121:30008/hubble/hubble_test
jdbc.hubble.username=hubble
jdbc.hubble.password=

#spark.local=false
spark.local=true
spark.local.taskid.session=1
spark.local.taskid.page=2
spark.local.taskid.product=3
spark.local.taskid.area=4

#kafka集群配置
metadata.broker.list=192.168.145.101:9092,192.168.145.102:9092,192.168.145.103:9092
kafka.serializer.StringEncoder=kafka.serializer.StringEncoder
kafka.serializer.StringEncoder=kafka.serializer.StringEncoder
kafka_request_required_acks=1
kafka_compression_codec=snappy
kafka_message_send_max_retries=2
kafka_reconnect_backoff_ms=100
kafka_request_timeout_ms=10000
kafka_producer_type=sync
kafka_queue_buffering_max_ms=
kafka_queue_buffering_max_messages=
kafka_queue_enqueue_timeout_ms=
kafka_batch_num_messages=
kafka_send_buffer_bytes=

#主题
kafka.topics=test
kafka.topics.key=dashboard

#模拟报文
kafka.topics.msg=1111222233333333333333333334444O5555555555666666666666 77788888888888899999999999999999999999999999900000000000000000000000000000000000000001        2222222222333333333333333V8888888888889999999999990000111222222222223345566666666666666666666666666666666666666666

#码表操作sql
dashboard.parse.rule.init=drop table if exists dashboard.datagram_parse_rule
dashboard.parse.rule.create=create table dashboard.datagram_parse_rule(var_trans varchar,var_id int,var_cn_name varchar,var_en_code varchar,var_length int,var_start_at int,var_end_at int,desc varchar)
dashboard.parse.rule.import=insert into dashboard.datagram_parse_rule(var_trans, var_id, var_cn_name, var_en_code, var_length, var_start_at, var_end_at, desc) values(?, ?, ?, ?, ?, ?, ?, ?)
dashboard.parse.rule.select=select * from dashboard.datagram_parse_rule
